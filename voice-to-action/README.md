# Voice Agent - Intelligent Voice Assistant with Browser Automation

A sophisticated voice-controlled AI assistant that seamlessly integrates conversational AI with browser automation. Built with a hybrid Swift + Python architecture for optimal performance and user experience.

## ğŸ¯ **What We're Building**

An intelligent voice assistant that:
- **Responds to questions** like "What is machine learning?" using conversational AI
- **Performs web actions** like "Go to Google and search for weather" using browser automation
- **Automatically decides** which type of response is needed based on your request
- **Works seamlessly with Wispr Flow** for speech-to-text transcription
- **Provides a minimal, Siri-like interface** that stays out of your way

## ğŸš€ **How It Works**

1. **Press and hold Option key** â†’ Minimal interface appears at top of screen
2. **Speak your request** â†’ Wispr Flow transcribes speech to text
3. **Release Option key** â†’ AI decides whether to respond conversationally or use browser
4. **Get your answer** â†’ Either direct text response or automated web actions
5. **Focus returns** â†’ Back to whatever you were doing

## ğŸ—ï¸ **Architecture Overview**

### **Swift macOS App** (Frontend & System Integration)
- ğŸ¨ **Minimal Siri-like UI** - Clean capsule interface with colorful gradient icon
- ğŸ”‘ **Global Option Key Detection** - Instant activation without interrupting workflow
- ğŸ–¥ï¸ **Smart Focus Management** - Seamlessly switches between apps
- âš¡ **Native macOS Performance** - Lightning-fast response times
- ğŸ¯ **Wispr Flow Integration** - Works perfectly with speech-to-text transcription

### **Python Backend** (AI Brain & Automation Engine)
- ğŸ§  **Dual Agent System** - LangChain for conversation + browser-use for automation
- ğŸ¤– **Intelligent Routing** - Automatically decides which agent to use
- ğŸŒ **Browser Automation** - Full web interaction capabilities via Playwright
- ğŸ“¡ **FastAPI Server** - High-performance REST API
- ğŸ”„ **Session Management** - Maintains context and conversation history

## ğŸš€ **Quick Start**

### **1. Start Python Backend**
```bash
cd python_backend
./start_server.sh
```

### **2. Start Swift App**
```bash
cd VoiceBrowserAgent.swiftpm
swift run
```
- Grant accessibility permissions when prompted
- App window appears at top-center of screen

### **3. Usage**
1. **Press Option key down** â†’ Minimal interface activates at top of screen
2. **Speak your request** â†’ Wispr Flow transcribes speech to text field
3. **Release Option key** â†’ AI processes and responds (conversation or browser action)
4. **Alternative:** Wait 3 seconds after speaking for auto-execution
5. **Click `?` button** â†’ View instructions and examples

## ğŸ“‹ **Setup Instructions**

### **Python Backend Setup**
```bash
cd python_backend

# Set OpenAI API key
export OPENAI_API_KEY='your-api-key-here'

# Install dependencies and start server
./start_server.sh
```

### **Swift App Setup**
1. Run `swift run` from the VoiceBrowserAgent.swiftpm directory
2. Grant **Accessibility** permissions when prompted:
   - System Preferences > Security & Privacy > Privacy > Accessibility
   - Enable VoiceBrowserAgent to monitor Option key globally

## ğŸ”— **Communication Flow**

```
1. Option Key Press â†’ Swift App Activates
2. Wispr Flow â†’ Text Input
3. Option Key Release â†’ HTTP POST /execute
4. Python Backend â†’ Analyzes Request Intent
5. Route Decision:
   â”œâ”€â”€ Conversational AI (LangChain) â†’ Direct Response
   â””â”€â”€ Browser Automation (browser-use) â†’ Web Actions
6. Response â†’ Swift App â†’ User
7. Focus Restoration â†’ Previous App
```

## ğŸ“ **Project Structure**

```
voice-to-action/
â”œâ”€â”€ README.md                          # This documentation
â”œâ”€â”€ VoiceBrowserAgent.swiftpm/         # Swift Package (macOS App)
â”‚   â”œâ”€â”€ Package.swift                 # Swift Package configuration
â”‚   â””â”€â”€ Sources/                      # Swift source files
â”‚       â”œâ”€â”€ main.swift                # App entry point & window setup
â”‚       â”œâ”€â”€ AppDelegate.swift         # App lifecycle & permissions
â”‚       â”œâ”€â”€ AppState.swift            # Option key monitoring & state
â”‚       â”œâ”€â”€ ContentView.swift         # Minimal Siri-like UI
â”‚       â”œâ”€â”€ SettingsView.swift        # Settings interface
â”‚       â””â”€â”€ BackendService.swift      # HTTP client for Python API
â””â”€â”€ python_backend/                   # Python AI Backend
    â”œâ”€â”€ browser_agent_api.py          # Dual-agent FastAPI server
    â”œâ”€â”€ requirements.txt              # Python dependencies
    â”œâ”€â”€ start_server.sh               # Auto-setup & start script
    â”œâ”€â”€ .env                          # OpenAI API key
    â””â”€â”€ .venv/                        # Virtual environment
```

## ğŸ¯ **Key Benefits of Hybrid Architecture**

### **Swift Side Advantages:**
- âš¡ **Lightning-fast** window switching (no subprocess calls)
- ğŸ **Native macOS experience** with proper focus management
- ğŸ”‘ **Reliable global hotkeys** using KeyboardShortcuts framework
- ğŸ¨ **Beautiful SwiftUI interface** with smooth animations
- ğŸ“¡ **System integration** that "just works"

### **Python Side Advantages:**
- ğŸ¤– **Proven browser-use integration** (no porting needed)
- ğŸ”§ **Rich Python ecosystem** for AI/LLM tasks
- ğŸ“š **Easy to modify and extend** browser automation logic
- ğŸ§ª **Simple to test and debug** backend functionality

## ğŸ› ï¸ **API Endpoints**

### **Health Check**
```http
GET http://localhost:8000/health
```

### **Execute Command**
```http
POST http://localhost:8000/execute
Content-Type: application/json

{
    "command": "Go to Google and search for OpenAI",
    "headless": false
}
```

## ğŸ”§ **Configuration**

### **Environment Variables** (python_backend/.env)
```bash
OPENAI_API_KEY=your-openai-api-key-here
```

### **Swift App Settings**
- Keyboard shortcuts (customizable via Settings)
- Backend URL configuration
- Auto-execute delay settings

## ğŸ§ª **Testing**

### **Test Backend Only**
```bash
cd python_backend
source .venv/bin/activate
python browser_agent_api.py

# In another terminal
curl http://localhost:8000/health
```

### **Test Full Integration**
1. Start Python backend
2. Run Swift app
3. Press Option key â†’ App should activate
4. Type "go to google" â†’ Release Option â†’ Should execute

## ğŸš¨ **Troubleshooting**

### **Backend Issues**
- **"LLM not initialized"**: Check OPENAI_API_KEY is set
- **"Connection refused"**: Ensure backend is running on port 8000
- **"Module not found"**: Run `pip install -r requirements.txt`

### **Swift App Issues**
- **Option key not working**: Grant Accessibility permissions
- **App won't activate**: Grant Automation permissions  
- **Build errors**: Ensure Xcode 15+ and macOS 14+

### **Integration Issues**
- **"Backend not running"**: Start Python server first
- **Commands not executing**: Check backend logs for errors
- **Focus not restoring**: Restart Swift app

## ğŸ”® **Future Enhancements**

- ğŸ“± Menu bar integration
- ğŸ”Š Voice feedback/confirmation
- ğŸ“ Command templates & shortcuts
- ğŸŒ Multiple browser support
- ğŸ“Š Usage analytics & insights
- ğŸ”„ Session persistence across restarts

## ğŸ“„ **License**

This project is provided as-is for demonstration purposes.